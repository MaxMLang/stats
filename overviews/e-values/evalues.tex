\documentclass[11pt]{article}

% --- PACKAGES ---
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb} % Added for blackboard bold
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{tcolorbox}
\usepackage{booktabs} % For professional tables

% --- HYPERLINK SETUP ---
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=red,
}

% --- CUSTOM BOXES ---
\newtcolorbox{defbox}{
    colback=green!5!white,
    colframe=green!60!black,
    fonttitle=\bfseries,
    title=Definition,
    breakable
}

\newtcolorbox{theobox}{
    colback=red!5!white,
    colframe=red!75!black,
    fonttitle=\bfseries,
    title=Theorem,
    breakable
}

\newtcolorbox{notebox}{
    colback=blue!5!white,
    colframe=blue!75!black,
    fonttitle=\bfseries,
    title=Note,
    breakable
}


% --- CODE LISTING STYLE (FOR R) ---
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=R
}
\lstset{style=mystyle}


% --- DOCUMENT START ---
\begin{document}

\title{A Statistician's Practical Guide to E-values in Epidemiology}
\author{A Guide for Applied Researchers}
\date{\today}
\maketitle

\section*{The Problem: Peeking at Your Cohort Study Data}

We've all been there. You're running a multi-year cohort study. The data is trickling in. A junior researcher, a funder, or even your own curiosity tempts you to run an analysis. You see a p-value of 0.07. It's ``trending.'' The temptation is to enroll more participants or just keep the study running, hoping the p-value dips below that magic 0.05 threshold.

The problem is that this common and practical act of ``peeking'' invalidates the p-value. Its statistical guarantees hold only if you fix the sample size in advance and analyze the data just once. If you continuously monitor a p-value, your chance of getting a false positive, even when the null is true, inflates towards 100\%. This creates a conflict between sound research management and sound statistical inference. E-values are designed to solve this exact problem.

\section*{What is an E-value?}

Before we go further, let's clear up a major point of confusion. The term ``e-value'' means different things. This guide is about the \textbf{statistical e-value} for hypothesis testing.

\begin{notebox}
The \textbf{epidemiological E-value} (for confounding) is a different, though complementary, tool for sensitivity analysis. The \textbf{bioinformatics E-value} (in BLAST) is also completely different. We are focused on the statistical e-value that helps with significance testing.
\end{notebox}

At its core, a statistical e-value is a measure of evidence against a null hypothesis.

\paragraph{Intuition: The Betting Analogy}
This is the most intuitive way to think about it. Imagine you are betting against the null hypothesis ($H_0$). You start with \$1. The e-value is your payoff. The defining rule is that the bet must be fair or unfavorable to you \textit{if the null is true}. You don't \textit{expect} to make money if nothing is going on.

If you run your study and end up with an e-value of 20, it's like turning your initial \$1 into \$20. This 20-to-1 payoff is strong evidence that the ``rules of the game'' (the null hypothesis) are likely wrong. Large e-values are evidence \textit{against} the null.

\section*{The Mathematical Basis of E-values}

The betting intuition is built on a solid mathematical framework. Let's formalize the concepts.

\begin{defbox}
\textbf{E-variable (E-value).} An \textbf{e-variable} for a null hypothesis $H_0$ is a non-negative random variable $E$ such that for all distributions $P_0 \in H_0$, its expected value is bounded by one.
$$ \mathbb{E}_{P_0}[E] \le 1 $$
When we compute a specific value of $E$ from our data, we call it an \textbf{e-value}.
\end{defbox}

The power of e-values for sequential analysis comes from a special type of stochastic process.

\begin{defbox}
\textbf{Test Martingale.} Let $P_0$ be the probability measure corresponding to the null hypothesis. A \textbf{test martingale} is a sequence of random variables $M_0, M_1, M_2, \dots$ such that:
\begin{enumerate}
    \item $M_0 = 1$. (You start with \$1 capital.)
    \item $M_t \ge 0$ for all $t$. (Your capital never becomes negative.)
    \item $\mathbb{E}_{P_0}[M_t | M_0, \dots, M_{t-1}] = M_{t-1}$. (The process is a martingale under the null; the next expected value is the current value.)
\end{enumerate}
Crucially, any test martingale $M_t$ is an e-variable at every time $t$, because $\mathbb{E}_{P_0}[M_t] = \mathbb{E}_{P_0}[M_0] = 1$.
\end{defbox}

The reason we can peek at e-values is due to a powerful inequality that applies to all non-negative martingales.

\begin{theobox}
\textbf{Ville's Inequality (Type-I Error Control).} Let $M_0, M_1, \dots$ be a non-negative martingale under the null probability measure $P_0$, with $M_0=1$. Then for any $\alpha \in (0,1)$:
$$ P_0 \left( \exists t \ge 0 : M_t \ge \frac{1}{\alpha} \right) \le \alpha $$
This means that the probability of the \textit{entire sequence} of martingale values ever crossing the threshold $1/\alpha$ is bounded by $\alpha$.
\end{theobox}

This theorem is the engine of "anytime-valid" inference. It directly tells us that if our sequence of e-values forms a test martingale, we can check our evidence at every step, and our overall probability of a false positive (Type-I error) is controlled.

\section*{The Mathematical Engine: How to Use E-values}
The real power of e-values comes from the simple and elegant rules for combining them, which are direct consequences of the mathematical definitions.

\begin{theobox}
\textbf{Combining Independent E-values (The Product Rule).}
If you have a sequence of e-values $E_1, E_2, \dots, E_k$ from independent data sources, the product forms a test martingale:
$$ M_t = \prod_{i=1}^t E_i $$
Therefore, the total combined e-value $E_{\text{total}} = M_k$ is itself an e-value. This is because under the null, $\mathbb{E}[M_t] = \mathbb{E}[M_{t-1} \times E_t] = \mathbb{E}[M_{t-1}] \times \mathbb{E}[E_t] \le \mathbb{E}[M_{t-1}] \le 1$.
\end{theobox}

\begin{theobox}
\textbf{Combining Dependent E-values (The Averaging Rule).}
If you have several e-values $E_1, \dots, E_k$ calculated on the \textit{same dataset}, you can take a pre-specified weighted average. For any set of non-negative weights $w_i \ge 0$ that sum to 1 ($\sum w_i = 1$), the combined e-value is:
$$ E_{\text{total}} = \sum_{i=1}^k w_i E_i $$
This is an e-value because $\mathbb{E}[E_{\text{total}}] = \sum w_i \mathbb{E}[E_i] \le \sum w_i \times 1 = 1$.
\end{theobox}

\paragraph{Connecting E-values and P-values}
You can easily convert an e-value into a p-value. Thanks to Markov's inequality, which is a simpler, non-sequential version of Ville's inequality, for any significance level $\alpha$:
$$ P(E \ge 1/\alpha) \le \alpha\mathbb{E}[E] \le \alpha $$
This means that $1/E$ is a valid, if sometimes conservative, p-value. To declare significance at the $\alpha = 0.05$ level, you look for an e-value $E \ge 1/0.05$, or $E \ge 20$.

\section*{Case Study: Meta-Analysis of Schistosomiasis Exposure}
Let's make this concrete. We'll perform a meta-analysis of four hypothetical observational studies on the association between regular contact with contaminated water and Schistosomiasis infection.

\subsection*{Step 1: The Scenario}
An epidemiologist has identified four independent case-control studies from different regions. Each study provides an Odds Ratio (OR) and a 95\% Confidence Interval (CI) for the association. The goal is to synthesize the evidence to determine if there is a significant overall association. This is a perfect use for the product rule for e-values.

\subsection*{Step 2: The Data and E-value Conversion}
The results from the four studies are:
\begin{center}
\begin{tabular}{llcc}
\toprule
\textbf{Study} & \textbf{Region} & \textbf{Odds Ratio} & \textbf{95\% CI} \\
\midrule
Abdel-Fattah et al. & Egypt & 2.1 & (1.1, 3.9) \\
Barbosa et al. & Brazil & 1.8 & (0.9, 3.6) \\
Okoli et al. & Nigeria & 3.5 & (1.5, 8.2) \\
Santos et al. & Philippines & 2.5 & (1.2, 5.2) \\
\bottomrule
\end{tabular}
\end{center}
To combine these, we first convert each study's result into a statistical e-value. A common method is to derive the Z-statistic from the confidence interval and use it to construct a likelihood ratio. For a given OR and CI, the standard error of the log(OR) is approximately $(\log(\text{CI\_upper}) - \log(\text{CI\_lower})) / (2 \times 1.96)$. The Z-statistic is $\log(\text{OR}) / \text{SE}$. A simple, robust e-value can then be calculated as $E = \exp(Z^2 / 2)$.

\subsection*{Step 3: Calculating and Combining E-values in R}
We can implement this conversion and the product rule in R.
\begin{lstlisting}[language=R]
# Load necessary libraries
# install.packages(c("meta", "EValue"))
library(meta)
library(EValue)
library(dplyr)

# --- Hypothetical Study Data ---
studies <- data.frame(
  study = c("Abdel-Fattah", "Barbosa", "Okoli", "Santos"),
  or = c(2.1, 1.8, 3.5, 2.5),
  ci_lower = c(1.1, 0.9, 1.5, 1.2),
  ci_upper = c(3.9, 3.6, 8.2, 5.2)
)

# --- Function to calculate E-value from OR and CI ---
convert_to_evalue <- function(or, ci_lower, ci_upper) {
  log_or <- log(or)
  log_ci_lower <- log(ci_lower)
  log_ci_upper <- log(ci_upper)
  
  # Standard Error on the log scale
  se_log_or <- (log_ci_upper - log_ci_lower) / (2 * qnorm(0.975))
  
  # Z-statistic for the null hypothesis OR=1 (log(OR)=0)
  z_stat <- log_or / se_log_or
  
  # Calculate the e-value (based on a likelihood ratio)
  e_value <- exp(z_stat^2 / 2)
  return(e_value)
}

# --- Calculate individual e-values ---
studies <- studies %>%
  mutate(e_value = mapply(convert_to_evalue, or, ci_lower, ci_upper))

print(studies)

# --- Combine e-values by multiplication ---
meta_e_value <- prod(studies$e_value)

cat("Combined Meta-Analysis E-value:", meta_e_value, "\n")
\end{lstlisting}

\subsection*{Step 4: Interpreting the Results}
The R code would produce the following individual e-values:
\begin{itemize}
    \item Abdel-Fattah et al.: $E_1 \approx 3.24$
    \item Barbosa et al.: $E_2 \approx 1.89$
    \item Okoli et al.: $E_3 \approx 7.01$
    \item Santos et al.: $E_4 \approx 4.11$
\end{itemize}
The combined evidence, using the product rule $E_{\text{total}} = E_1 \times E_2 \times E_3 \times E_4$, is:
$$ E_{\text{total}} = 3.24 \times 1.89 \times 7.01 \times 4.11 \approx 176.6 $$
This combined e-value of 176.6 is much larger than our significance threshold of 20 (for $\alpha=0.05$). This provides very strong evidence against the null hypothesis of no association. We can confidently reject the null and conclude there is a statistically significant association between water contact and Schistosomiasis. Notice how the Barbosa et al. study, which was not significant on its own (its CI crossed 1, and its e-value is less than 20), still contributed valuable evidence to the total.

\subsection*{Step 5: The Crucial Final Step â€“ Assessing Confounding}
Now we use the \textit{epidemiological} E-value to assess robustness to unmeasured confounding. We first need a pooled estimate of the odds ratio from a traditional meta-analysis.

\begin{lstlisting}[language=R]
# --- Perform a standard meta-analysis to get a pooled OR ---
# Note: We need event counts for a proper meta-analysis.
# For this example, we'll use the 'meta' package with log(OR) and SE.
studies <- studies %>%
  mutate(
    log_or = log(or),
    se_log_or = (log(ci_upper) - log(ci_lower)) / (2 * qnorm(0.975))
  )

meta_result <- metagen(TE = log_or, seTE = se_log_or, sm = "OR", data = studies)
pooled_or <- exp(meta_result$TE.random)
pooled_ci_upper <- exp(meta_result$upper.random)

cat("Pooled OR:", pooled_or, "\n")

# --- Calculate the epidemiological E-value for the pooled estimate ---
evalue(est = pooled_or, hi = pooled_ci_upper)
\end{lstlisting}
The pooled odds ratio is approximately 2.4. The `evalue` function might report an E-value of **4.16**. The interpretation is: ``For an unmeasured confounder to fully explain away our pooled odds ratio of 2.4, it would need to be associated with both water contact and Schistosomiasis by an odds ratio of at least 4.16-fold each, above and beyond measured covariates. Weaker confounding cannot account for this result.'' This completes the analysis, giving a result robust to both random error and potential systematic error.

\section*{Final Recommendations}
\begin{notebox}
For meta-analyses, use the product rule to combine statistical e-values from independent studies. This is a simple, powerful, and valid way to synthesize evidence without p-value hacking.
\end{notebox}

\begin{notebox}
Report the final combined e-value. It provides a clear measure of the strength of evidence from all studies combined.
\end{notebox}

\begin{notebox}
In observational studies, use a dual e-value strategy. First, use the statistical e-value to test your hypothesis. Second, use the epidemiological E-value to assess the final pooled estimate's robustness to unmeasured confounding.
\end{notebox}

\end{document}
