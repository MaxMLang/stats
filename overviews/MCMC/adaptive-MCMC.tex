\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{biblatex}
\addbibresource{references.bib}
\title{Overview of Adaptive MCMC Sampling}
\author{}
\date{}

\begin{document}
\maketitle
This document is based on \textcite{andrieu_tutorial_2008} 's tutotrial on adaptive MCMC, which is highly recommended read.
\section{Traditional MCMC Sampling}
Markov Chain Monte Carlo (MCMC) is a family of algorithms that sample from probability distributions by constructing a Markov chain that has the desired distribution as its equilibrium distribution. 

ve to a new state and accepts or rejects this state based on an acceptance probability, ensuring convergence to the target distribution.

\section{Adaptive MCMC Sampling}
Adaptive MCMC improves upon the traditional method by dynamically adjusting its parameters during the sampling process.

\subsection{Transition Kernel Adaptation}
\begin{itemize}
    \item \textbf{Traditional MCMC:} Fixed transition kernel.
    \item \textbf{Adaptive MCMC:} Transition kernel that changes during sampling to improve efficiency.
\end{itemize}

\subsection{Non-Homogeneity}
\begin{itemize}
    \item \textbf{Traditional MCMC:} Homogeneous Markov chain.
    \item \textbf{Adaptive MCMC:} Non-homogeneous chain complicates mathematical analysis.
\end{itemize}

\subsection{Stochastic Approximation in MCMC}
Stochastic approximation is a framework for finding the roots of a function when the function cannot be measured directly but can be estimated via noisy observations. In the context of MCMC, stochastic approximation methods, such as the Robbins–Monro algorithm, are used to adaptively tune the parameters of the proposal distribution to achieve a desired acceptance rate.

\subsubsection{Robbins–Monro Algorithm}
The Robbins–Monro (RM) algorithm is a sequential estimation procedure that aims to find the root of an unknown function \( f(\theta) = 0 \) by iteratively updating the estimate \( \theta \) using noisy observations of \( f \). In MCMC, it is often used to adjust the scale parameter of the proposal distribution to achieve an optimal acceptance rate.

\paragraph{Application in MCMC:}
In adaptive MCMC using the RM update, the acceptance rate of the Metropolis-Hastings algorithm is monitored at each iteration. The goal is to adjust the scale of the proposal distribution so that this acceptance rate converges to a target value, typically around 0.234 for optimal mixing in high-dimensional settings. If the current acceptance rate is higher than the target, the scale is increased, encouraging broader exploration. Conversely, if the acceptance rate is too low, the scale is decreased to promote a higher acceptance rate.

\paragraph{Update Rule:}
The RM update rule can be formulated as:
\[
\theta_{n+1} = \theta_n + a_n(Y_n - \alpha),
\]
where \( \theta_n \) is the current parameter estimate, \( Y_n \) is the observed acceptance rate at the \( n \)-th iteration, \( \alpha \) is the target acceptance rate, and \( a_n \) is a sequence of positive step sizes satisfying certain conditions, typically \( a_n \to 0 \) as \( n \to \infty \) and \( \sum_{n=1}^{\infty} a_n = \infty \).

\paragraph{Convergence Conditions:}
For the RM procedure to converge to the true parameter value that sets \( f(\theta) = 0 \), the sequence of step sizes \( a_n \) must be chosen such that they decrease at an appropriate rate. The conditions \( \sum_{n=1}^{\infty} a_n = \infty \) and \( \sum_{n=1}^{\infty} a_n^2 < \infty \) ensure that the algorithm will not 'forget' the target too quickly, and will not be too 'noisy', respectively.

\paragraph{Benefits in MCMC:}
Incorporating the RM algorithm into MCMC allows for online adaptation of the proposal distribution, potentially leading to faster convergence and reduced autocorrelation in the sampled chain. However, the practitioner must be cautious to maintain the Markov property, ensuring that the adaptive process does not violate the conditions necessary for the theoretical guarantees of MCMC methods.


\subsection*{Convergence and Mathematical Complications of Adaptive MCMC}
The convergence of Adaptive Markov Chain Monte Carlo (MCMC) methods is a critical aspect that ensures the samples generated by the algorithm are representative of the target distribution. However, the adaptive nature of these methods introduces several mathematical complexities that must be addressed to guarantee convergence.

\subsubsection{Convergence Criteria}
For a Markov chain to converge to its stationary distribution, it must satisfy two main conditions: ergodicity and detailed balance. Ergodicity ensures that the chain is irreducible, aperiodic, and positive recurrent, which guarantees that long-run averages converge to expected values with respect to the stationary distribution. Detailed balance requires that the chain has time-reversal symmetry, which is a sufficient condition for the stationary distribution to be a fixed point of the transition kernel.

\subsubsection{Complications Due to Adaptation}
Adaptive MCMC methods modify the transition kernel based on the history of the sampled chain, leading to a non-homogeneous Markov chain where standard convergence proofs do not apply. Here are some specific challenges:
\begin{itemize}
    \item \textbf{Loss of Markovian Property:} Adaptation can potentially violate the Markov property because the future state depends not only on the current state but also on the history of past states.
    \item \textbf{Time-Varying Transition Kernels:} The transition kernel changes over time, which means standard techniques for proving stationary and convergence to equilibrium are not directly applicable.
    \item \textbf{Design of Adaptation Schemes:} Creating adaptation schemes that guarantee convergence while still improving efficiency is challenging. The schemes must allow the algorithm to 'forget' its initial conditions and adapt appropriately to the target distribution.
\end{itemize}

\subsubsection{Ensuring Convergence}
To overcome these complications, adaptive MCMC algorithms are designed with certain safeguards:
\begin{itemize}
\item \textbf{Diminishing Adaptation:} \cite{andrieu_tutorial_2008} describe a strategy where the degree of adaptation is diminished over time by employing a sequence of step sizes \(\{ \gamma_i \}\) that are deterministic and non-increasing. An example of an update rule that illustrates this approach is:
\begin{equation*}
    \theta_{i+1} = \theta_{i} + \gamma_{i+1} \left( I\{\hat{\alpha}_{\theta_i} - \bar{\alpha}^* > 0\} - I\{\hat{\alpha}_{\theta_i} - \bar{\alpha}^* \leq 0\} \right),
\end{equation*}
where \(\theta_i\) is the current parameter estimate, \(\gamma_{i+1}\) is the step size, \(\hat{\alpha}_{\theta_i}\) is the estimated acceptance rate, and \(\bar{\alpha}^*\) is the target acceptance rate. This mechanism ensures that the variations of the parameter updates vanish, leading to a homogeneous Markov chain in the long run.

\item \textbf{Containment Conditions:} The adaptive step sizes can also be chosen to be random, ensuring that parameter updates are contained within a specific range. For instance, by setting the step sizes to take values in \(\{\delta, 0\}\) with a positive number \(\delta\), and allowing the probability \(P(\gamma_i = \delta)\) to follow a deterministic and non-increasing sequence \(\{p_i\}\), the parameters are prevented from diverging. This controlled randomness acts as a containment condition.

\item \textbf{Validation Techniques:} The principle of diminishing adaptation acts as an implicit validation technique, ensuring that the parameters converge over time. The chosen sequence \(\{\gamma_i\}\), which decreases appropriately, implicitly validates the convergence of the algorithm.
\end{itemize}

\section{Adaptive MCMC Algorithms}

\subsection{Algorithm 1: Adaptive Metropolis (AM)}

\subsubsection{Mathematical Explanation}
The AM algorithm dynamically adjusts the proposal distribution's mean and covariance matrix using past samples to improve the exploration of the target distribution. Given the current state \(X_i\), mean \(\mu_i\), and covariance matrix \(\Sigma_i\), the update rules are:
\begin{align*}
\mu_{i+1} &= \mu_i + \gamma_{i+1}(X_{i+1} - \mu_i), \\
\Sigma_{i+1} &= \Sigma_i + \gamma_{i+1}((X_{i+1} - \mu_i)(X_{i+1} - \mu_i)^\top - \Sigma_i).
\end{align*}
The step size \(\gamma_{i+1}\) decreases with iterations to ensure convergence.

\subsubsection{Intuitive Explanation}
The AM algorithm resembles a person walking through a hilly terrain blindfolded, where each step is informed by the feedback from previous steps. By adjusting the direction and length of steps based on past experience, the walker becomes more adept at navigating the terrain.

\subsubsection{Advantages and Disadvantages}
\paragraph{Advantages:}
\begin{itemize}
    \item Improves sampling efficiency by adapting to the target distribution's shape.
    \item Reduces the need for manual tuning of the proposal distribution.
\end{itemize}

\paragraph{Disadvantages:}
\begin{itemize}
    \item Initial convergence can be slow if starting far from the target distribution.
    \item Requires careful design to ensure theoretical properties like ergodicity are maintained.
\end{itemize}

\subsubsection{Applications}
The AM algorithm is applied in Bayesian statistics for parameter estimation where the posterior distribution is complex, like in hierarchical models or models with many parameters.

\subsubsection{Python Implementation}
The Python pseudocode for the AM algorithm is embedded in LaTeX for illustrative purposes:
\begin{verbatim}
def adaptive_metropolis(X_0, mu_0, Sigma_0, gamma, n_iterations):
    X = X_0
    mu = mu_0
    Sigma = Sigma_0
    for i in range(1, n_iterations):
        X_new = sample_from_proposal(X, mu, Sigma)
        if accept(X_new):
            X = X_new
        mu = mu + gamma(i) * (X - mu)
        Sigma = Sigma + gamma(i) * (np.outer(X - mu, X - mu) - Sigma)
    return X, mu, Sigma
\end{verbatim}

\subsection{Algorithm 2: Rao-Blackwellised AM Algorithm}

\subsubsection{Mathematical Explanation}
The Rao-Blackwellised Adaptive Metropolis (RB-AM) algorithm aims to reduce the variance of the sample estimators by incorporating Rao-Blackwellisation into the updating step of the AM algorithm. The updates for the mean and covariance matrix at iteration \( i+1 \) are given by:
\begin{align*}
\mu_{i+1} &= \mu_i + \gamma_{i+1}(\bar{X}_{i+1} - \mu_i), \\
\Sigma_{i+1} &= \Sigma_i + \gamma_{i+1}((X_{i+1} - \mu_i)(X_{i+1} - \mu_i)^\top - \Sigma_i).
\end{align*}
Here, \(\bar{X}_{i+1}\) represents the Rao-Blackwellised estimate of \(X_{i+1}\), which is a conditional expectation considering both the proposal and the current state.

\subsubsection{Intuitive Explanation}
RB-AM can be likened to a feedback system that not only adjusts based on where it currently is but also considers where it could have been, thereby providing a more informed update at each step. This process helps in smoothing out the update path by reducing the noise associated with the sampling process.

\subsubsection{Advantages and Disadvantages}
\paragraph{Advantages:}
\begin{itemize}
    \item Potentially more efficient sampling due to variance reduction.
    \item Can provide better estimates with the same number of samples compared to standard AM.
\end{itemize}

\paragraph{Disadvantages:}
\begin{itemize}
    \item May require additional computational resources due to the calculation of conditional expectations.
    \item The benefits in variance reduction might not always outweigh the additional computational cost.
\end{itemize}

\subsubsection{Applications}
RB-AM can be particularly beneficial in high-dimensional problems where variance reduction is crucial, such as in financial risk modeling or complex Bayesian statistical models.

\subsubsection{Python Implementation}
\begin{verbatim}
def rao_blackwellised_am(X_0, mu_0, Sigma_0, gamma, n_iterations):
    X = X_0
    mu = mu_0
    Sigma = Sigma_0
    for i in range(1, n_iterations):
        Y_new = sample_normal(X, Sigma)
        X_new = Y_new if accept(X, Y_new) else X
        X_bar = compute_rao_blackwellised_estimate(X, Y_new)
        mu = mu + gamma(i) * (X_bar - mu)
        Sigma = Sigma + gamma(i) * (np.outer(X_new - mu, X_new - mu) - Sigma)
    return X, mu, Sigma

# Note: Implementations of sample_normal, accept, and compute_rao_blackwellised_estimate are required.
\end{verbatim}

\subsection{Algorithm 3: AM Algorithm with Global Adaptive Scaling}

\subsubsection{Mathematical Explanation}
This algorithm introduces a global adaptive scaling factor \(\lambda_i\) to the standard AM algorithm. At each iteration \(i+1\), given the current state \(X_i\), mean \(\mu_i\), covariance matrix \(\Sigma_i\), and scaling factor \(\lambda_i\), the updates are as follows:
\begin{align*}
X_{i+1} &\sim \mathcal{N}(X_i, \lambda_i \Sigma_i), \\
\log(\lambda_{i+1}) &= \log(\lambda_i) + \gamma_{i+1}(\alpha(X_i, Y_{i+1}) - \bar{\alpha}^*), \\
\mu_{i+1} &= \mu_i + \gamma_{i+1}(X_{i+1} - \mu_i), \\
\Sigma_{i+1} &= \Sigma_i + \gamma_{i+1}((X_{i+1} - \mu_i)(X_{i+1} - \mu_i)^\top - \Sigma_i).
\end{align*}
Here, \(\bar{\alpha}^*\) is a target acceptance rate, and \(\gamma_{i+1}\) is a step size parameter. The scaling factor \(\lambda_i\) is adjusted based on the acceptance rate, with the goal of optimizing the exploration of the target distribution.

\subsubsection{Intuitive Explanation}
The global adaptive scaling factor acts like a zoom lens on a camera, adjusting the focus to ensure that the features of the target distribution are captured efficiently. If the acceptance rate indicates that the "picture" is too blurry (due to an inappropriate scaling factor), the "zoom" adjusts to bring the distribution into clearer view for better exploration.

\subsubsection{Advantages and Disadvantages}
\paragraph{Advantages:}
\begin{itemize}
    \item Offers a more flexible adaptation by scaling the proposal distribution globally, which can lead to better exploration.
    \item Can dynamically adjust to the "difficulty" of exploring the target distribution, reflected by the acceptance rate.
\end{itemize}

\paragraph{Disadvantages:}
\begin{itemize}
    \item May require careful tuning of the adaptation step size to ensure stability and good performance.
    \item Global scaling may not be suitable for all problems, especially if different parameters require scaling at different rates.
\end{itemize}

\subsubsection{Applications}
The AM algorithm with global adaptive scaling is useful in scenarios where the scale of the target distribution is not well known in advance, such as in complex Bayesian models where the posterior landscape is not well understood before sampling.

\subsection{Algorithm 4: Componentwise AM with Componentwise Adaptive Scaling}

\subsubsection{Mathematical Explanation}
The Componentwise AM algorithm with componentwise adaptive scaling modifies the proposal distribution by independently adapting the scaling for each component of the parameter vector. The updates are executed as follows:
\begin{align*}
\text{Choose component } k &\sim U\{1, \dots, n_x\}, \\
Y_{i+1} &\sim \mathcal{N}(X_i + e_k, \lambda_{ki} \Sigma_{ii}[k,k]), \\
X_{i+1} &= 
\begin{cases} 
Y_{i+1} & \text{with probability } \alpha(X_i, Y_{i+1}), \\
X_i & \text{otherwise},
\end{cases} \\
\log(\lambda_{k,i+1}) &= \log(\lambda_{ki}) + \gamma_{i+1}(\alpha(X_i, Y_{i+1}) - \bar{\alpha}^{\ast\ast}), \\
\mu_{i+1} &= \mu_i + \gamma_{i+1}(X_{i+1} - \mu_i), \\
\Sigma_{i+1} &= \Sigma_i + \gamma_{i+1}((X_{i+1} - \mu_i)(X_{i+1} - \mu_i)^\top - \Sigma_i), \\
\lambda_{j,i+1} &= \lambda_{ji} \text{ for } j \neq k.
\end{align*}
In this scheme, \( e_k \) is the unit vector with a one in the \( k \)-th position, \( \Sigma_{ii}[k,k] \) is the \( k \)-th diagonal element of \( \Sigma_i \), and \( \bar{\alpha}^{\ast\ast} \) is a target acceptance rate.

\subsubsection{Intuitive Explanation}
Imagine each parameter in a multi-dimensional space being fine-tuned by its own dedicated mechanic, ensuring that each one operates at an individually optimized pace. This componentwise approach allows each dimension to "learn" from its own history, potentially leading to more efficient exploration when different scales are needed for different directions in the parameter space.

\paragraph{Advantages and Disadvantages}
\paragraph{Advantages:}
\begin{itemize}
    \item Allows for individualized scaling, which can be beneficial in high-dimensional problems with parameters that have differing scales.
    \item Potentially improves convergence by adapting to the unique features of the distribution along each dimension.
\end{itemize}

\paragraph{Disadvantages:}
\begin{itemize}
    \item Increases computational complexity with the number of parameters due to individual scaling factors.
    \item May require more iterations to achieve convergence for all parameters, especially in very high-dimensional spaces.
\end{itemize}

\subsubsection{Applications}
This approach is particularly useful in situations where the target distribution has different variances across dimensions, such as in models with heterogeneous parameters, where each parameter might require a different exploration strategy due to different scales or correlations with other parameters.

\subsection{Algorithm 5: Global AM with Componentwise Adaptive Scaling}

\paragraph{Mathematical Explanation}
This version of the Adaptive Metropolis algorithm adjusts the proposal distribution by using both global and componentwise adaptive scaling. At each iteration \(i+1\), the algorithm proceeds with the following steps:
\begin{enumerate}
    \item Sample \( Z_{i+1} \) from a multivariate normal distribution with mean 0 and covariance matrix scaled by \( \Lambda_i^{1/2} \), where \( \Lambda_i \) is a diagonal matrix composed of the componentwise scaling factors \( \lambda_{1i}, \ldots, \lambda_{ni_x} \).
    \item Update each scaling factor \( \lambda_{ki} \) based on the acceptance probability of the move in each component direction, aiming to adjust the exploration of the parameter space adaptively.
    \item Modify the global position \( X_{i+1} \) and the covariance matrix \( \Sigma_{i+1} \) as in the standard AM algorithm, but informed by the componentwise adaptation.
\end{enumerate}

\paragraph{Intuitive Explanation}
Think of this algorithm as a squad of scouts each equipped with their own telescope, adjusting their lenses individually while also moving together as a group. This dual adjustment allows for a more nuanced exploration of the terrain, with each scout focusing on the details in their view while the group moves towards a common goal.

\paragraph{Advantages and Disadvantages}
Advantages:
\begin{itemize}
    \item Fine-tunes the scale of exploration in each dimension, potentially leading to more efficient sampling in complex, high-dimensional spaces.
    \item Balances global and local exploration, which can be beneficial when different parameters or groups of parameters exhibit different levels of variability.
\end{itemize}

Disadvantages:
\begin{itemize}
    \item Increased computational complexity due to the need to compute acceptance probabilities for each dimension.
    \item May require careful calibration of componentwise scaling factors to ensure effective global exploration.
\end{itemize}

\paragraph{Applications}
The Global AM algorithm with componentwise adaptive scaling is well-suited for problems where parameters have different scales or the target distribution exhibits anisotropic behavior. It can be particularly beneficial in fields such as machine learning and computational physics, where models often include parameters with diverse behaviors and scales.

\subsection{Algorithm 6: Localised N-SRWM Algorithm}

This algorithm localizes the updates in the state-dependent Random Walk Metropolis (SRWM), aiming to improve the efficiency of the sampling in high-dimensional spaces.

\subsubsection{Mathematical Explanation}
At each iteration \(i+1\), the algorithm selects a component \(k\) and proposes a new state \(Y_{i+1}\) using a localized proposal distribution \(\mathcal{N}(X_i, \lambda_{ki} \Sigma_{i})\). The acceptance of the proposed state \(Y_{i+1}\) is then determined based on the localized acceptance probability, and the updates for the mean and scaling factor are adjusted accordingly.

\subsubsection{Intuitive Explanation}
The Localised N-SRWM algorithm is akin to navigating a complex landscape by focusing on one region at a time. By concentrating on localized areas, it can more efficiently explore each section before moving on to the next, potentially avoiding pitfalls that a more global approach might encounter.

\subsubsection{Advantages and Disadvantages}
\paragraph{Advantages}
\begin{itemize}
    \item Focused exploration can lead to faster convergence in localized areas of the parameter space.
    \item May be more efficient in high-dimensional spaces where global moves are often rejected.
\end{itemize}

\paragraph{Disadvantages}
\begin{itemize}
    \item May require more iterations to explore the entire parameter space due to the localized nature of the updates.
    \item Might miss global structure of the target distribution if too concentrated on local features.
\end{itemize}

\subsubsection{Applications}
This algorithm is useful for problems with a complex parameter space where the target distribution may have multiple modes or areas of interest that are well-separated, requiring focused exploration.

\subsection{Algorithm 7: Principal Components Metropolis Update}

\subsubsection{Mathematical Explanation}
This adaptive MCMC algorithm employs principal component analysis (PCA) to inform the proposal distribution in the Metropolis update. At iteration \(i + 1\), given the current state \(X_i\) and parameters \((\rho_i, W_i)\), the update proceeds as follows:
\begin{enumerate}
    \item Choose an update direction \(l\) from a predefined distribution over the principal components.
    \item Sample a perturbation \(Z_{i+1}\) from a normal distribution with mean \(0\) and covariance \(\rho_i(l) W_i(l)\), where \(\rho_i\) and \(W_i\) are the eigenvalues and eigenvectors from PCA.
    \item Propose a new state \(Y_{i+1} = X_i + Z_{i+1} W_i(l)\) and accept it with a probability that ensures detailed balance with respect to the target distribution.
    \item Update the PCA parameters \((\rho_i, W_i)\) to \((\rho_{i+1}, W_{i+1})\) based on the newly accepted state.
\end{enumerate}

\subsubsection{Intuitive Explanation}
Imagine trying to navigate through a mountainous region by walking along the ridges and valleys. The Principal Components Metropolis Update is like using the topography of the landscape to guide your steps, where the ridges and valleys are the principal components determined by PCA. This method allows for movements that are aligned with the most significant features of the terrain, potentially leading to more direct and efficient exploration.
\subsubsection{Advantages and Disadvantages}
\paragraph{Advantages}
\begin{itemize}
    \item Utilizes the underlying structure of the target distribution for more informed proposal generation.
    \item Can lead to faster convergence by proposing moves along directions with higher variance.
\end{itemize}

\paragraph{Disadvantages}
\begin{itemize}
    \item Computationally more intensive due to the PCA calculations at each step.
    \item May not be as effective if the principal components do not capture important aspects of the target distribution's structure.
\end{itemize}

\subsubsection{Applications}
This algorithm is particularly useful in high-dimensional problems where the target distribution has a complex covariance structure that standard random walk proposals cannot efficiently explore.

\subsection{Algorithm 8: The Gaussian Copula SRWM}

\subsubsection{Mathematical Explanation}
The Gaussian copula Sequential Random Walk Metropolis (SRWM) algorithm is a type of MCMC that uses a Gaussian copula to define the proposal distribution. At each iteration \(i + 1\), given the current state \(X_i\), the algorithm updates as follows:
\begin{enumerate}
    \item Sample a perturbation \(Z = Z_i + W\), where \(W\) is drawn from a multivariate normal distribution with mean 0 and covariance \( \hat{\lambda} \).
    \item Modify \(X\) such that the indicator function \(I\{Z \in I_{X}\}\) equals 1, ensuring the proposed move remains within the desired state space.
    \item Update the state to \((X_{i+1}, Z_{i+1}) = (X, Z)\) with a probability that is the minimum between 1 and the ratio \(\frac{\tilde{\pi}_{\theta} (X, Z)}{\tilde{\pi}_{\theta} (X_i, Z_i)}\), ensuring the detailed balance condition is met.
\end{enumerate}
If the new state is not accepted, the algorithm retains the current state \( (X_{i+1}, Z_{i+1}) = (X_i, Z_i) \).

\subsubsection{Intuitive Explanation}
The Gaussian Copula SRWM can be thought of as an approach that allows for the inclusion of complex dependencies between the variables in the state space. By using a copula, it ties together the margins of the individual variables, allowing for a move that considers the joint distribution rather than independent updates.

\subsubsection{Advantages and Disadvantages}
\paragraph{Advantages}
\begin{itemize}
    \item It captures complex dependencies between the variables, which can be particularly advantageous in high-dimensional spaces.
    \item The use of copulas allows for more flexibility in constructing proposal distributions that more closely match the target distribution.
\end{itemize}

\paragraph{Disadvantages}
\begin{itemize}
    \item Computationally intensive due to the need to handle copula functions and ensure that proposed moves remain within the target distribution's support.
    \item May require sophisticated methods to estimate the parameters of the copula, which can be challenging in practice.
\end{itemize}

\subsubsection{Applications}
The Gaussian Copula SRWM algorithm is beneficial in scenarios where the target distribution exhibits complex dependencies that standard MCMC methods may not capture efficiently. It is often used in financial econometrics and risk management, where modeling joint movements of assets or risks is crucial.

\printbibliography
\end{document}
